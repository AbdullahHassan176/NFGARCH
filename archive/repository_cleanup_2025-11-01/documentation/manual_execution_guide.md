# Manual Engine Execution Guide - Complete Walkthrough

This guide walks you through running the Financial-SDG-GARCH pipeline step-by-step using the **manual engine only**, with mathematical verification at each step.

## üìã Prerequisites Check

### Step 1: Verify R Installation
```r
# In R Console or RStudio
R.version
# Should show R >= 4.0.0

# Install required packages
install.packages(c(
  "xts", "zoo", "PerformanceAnalytics", 
  "dplyr", "tidyr", "stringr", "lubridate",
  "parallel", "doParallel", "openxlsx", 
  "moments", "tseries", "forecast", 
  "ggplot2", "quantmod", "FinTS"
))
```

### Step 2: Verify Python Installation
```bash
python --version
# Should show Python >= 3.8

pip install torch nflows numpy pandas matplotlib scipy psutil
```

### Step 3: Verify Data File Exists
```r
file.exists("./data/processed/raw (FX + EQ).csv")
# Should return TRUE
```

---

## üî¨ Phase 1: Mathematical Verification (5 minutes)

**Purpose**: Verify the manual GARCH engine implements the correct mathematical equations.

### Step 1.1: Run Math Verification Script
```r
# In RStudio or R Console
source("scripts/manual/verify_manual_math.R")
```

**What this checks:**
- ‚úì sGARCH variance equation: œÉ¬≤_t = œâ + Œ±Œµ¬≤_{t-1} + Œ≤œÉ¬≤_{t-1}
- ‚úì eGARCH log-variance equation: log(œÉ¬≤_t) = œâ + Œ±(|z_{t-1}| - E|z_t|) + Œ≤log(œÉ¬≤_{t-1}) + Œ≥z_{t-1}
- ‚úì gjrGARCH variance equation: œÉ¬≤_t = œâ + Œ±Œµ¬≤_{t-1} + Œ≥Œµ¬≤_{t-1}I_{Œµ<0} + Œ≤œÉ¬≤_{t-1}
- ‚úì TGARCH variance equation: œÉ¬≤_t = œâ + (Œ± + Œ∑I_{Œµ<0})Œµ¬≤_{t-1} + Œ≤œÉ¬≤_{t-1}
- ‚úì Log-likelihood calculations for Normal and Student-t distributions
- ‚úì Parameter constraints (œâ > 0, Œ± ‚â• 0, Œ≤ ‚â• 0, Œ± + Œ≤ < 1)
- ‚úì Variance stationarity conditions

**Expected Output:**
```
=== MANUAL ENGINE MATH VERIFICATION ===
‚úì sGARCH variance recursion: PASSED
‚úì eGARCH log-variance recursion: PASSED  
‚úì gjrGARCH variance recursion: PASSED
‚úì TGARCH variance recursion: PASSED
‚úì Log-likelihood calculation: PASSED
‚úì Parameter constraints: PASSED
‚úì Stationarity conditions: PASSED
All mathematical verifications PASSED
```

**If verification fails:** Check the error messages and report issues.

---

## üìä Phase 2: Data Loading & EDA (10 minutes)

### Step 2.1: Load Data and Verify
```r
# In RStudio
setwd("C:/Github/Financial-SDG-GARCH")  # Adjust path as needed

# Load data
raw_price_data <- read.csv("./data/processed/raw (FX + EQ).csv", row.names = 1)
raw_price_data$Date <- lubridate::ymd(rownames(raw_price_data))
rownames(raw_price_data) <- NULL
raw_price_data <- raw_price_data %>% dplyr::select(Date, everything())

# Verify data structure
cat("Rows:", nrow(raw_price_data), "\n")
cat("Columns:", ncol(raw_price_data), "\n")
cat("Date range:", min(raw_price_data$Date), "to", max(raw_price_data$Date), "\n")
```

**Expected:** ~4500 rows, 13 columns (1 Date + 12 assets)

### Step 2.2: Calculate Returns
```r
# Extract price matrix
price_data_matrix <- raw_price_data[, !(names(raw_price_data) %in% "Date")]

# Calculate log returns
returns_matrix <- apply(price_data_matrix, 2, function(x) {
  diff(log(x))[-1]
})

# Verify returns statistics
summary(returns_matrix)
# Should show:
# - Mean near 0 for each asset
# - Non-zero standard deviation
# - Some negative values (losses)
```

**Mathematical Check:** For log returns r_t = log(P_t/P_{t-1}), verify:
- Mean should be approximately 0 (or small drift)
- Standard deviation > 0 (volatility)
- Negative skewness typical for financial returns

---

## üéØ Phase 3: Manual Optimized Configuration (2 minutes)

### Step 3.1: Load Optimized Configuration
```r
# Load manual optimization settings
source("scripts/manual/manual_optimized_config.R")

# Display configuration
print_optimization_summary()
```

**Expected Output:**
```
=== MANUAL EXECUTION OPTIMIZATION SUMMARY ===
Asset Reduction:  50 % ( 12  ->  6 )
Model Reduction:  40 % ( 5  ->  3 )
CV Optimization:  60 % time savings
Expected Total Time Savings: 70-80%
Expected Execution Time: 45-90 minutes
```

**Assets:** NVDA, MSFT, AMZN (Equity) + EURUSD, GBPUSD, USDZAR (FX)  
**Models:** sGARCH, eGARCH, TGARCH

---

## üîß Phase 4: GARCH Model Fitting (20-30 minutes)

### Step 4.1: Run Optimized GARCH Fitting
```r
# Run the manual GARCH fitting script
source("scripts/manual/manual_garch_fitting.R")
```

**What happens:**
1. Loads 6 optimized assets (3 FX + 3 Equity)
2. Calculates log returns for each asset
3. Fits 3 GARCH models (sGARCH, eGARCH, TGARCH) using **manual engine**
4. Extracts standardized residuals: z_t = Œµ_t / œÉ_t
5. Saves residuals for NF training

**Mathematical Verification During Fitting:**

For each model-asset combination, verify:
```r
# After fitting, check:
fit <- your_fit_object

# 1. Parameters satisfy constraints
fit$coef["omega"] > 0
fit$coef["alpha"] >= 0
fit$coef["beta"] >= 0
fit$coef["alpha"] + fit$coef["beta"] < 1  # Stationarity

# 2. Standardized residuals have mean ‚âà 0, variance ‚âà 1
mean(fit$std_residuals, na.rm = TRUE)
var(fit$std_residuals, na.rm = TRUE)

# 3. Residuals are uncorrelated (Ljung-Box test)
Box.test(fit$std_residuals, type = "Ljung-Box", lag = 10)

# 4. Squared residuals show no ARCH effects
Box.test(fit$std_residuals^2, type = "Ljung-Box", lag = 10)
```

**Expected Outputs:**
- `outputs/manual/garch_fitting/model_summary.csv` - Convergence status for each model
- `outputs/manual/residuals_by_model/` - Residuals organized by model type

**Key Metrics to Check:**
- Convergence rate should be > 90% for all models
- AIC/BIC values should be reasonable (no extreme values)
- Log-likelihood should be negative (normal for log-likelihood)

---

## ü§ñ Phase 5: Normalizing Flow Training (20-30 minutes)

### Step 5.1: Train NF Models
```python
# In Python/Jupyter Notebook or command line
python scripts/manual/manual_nf_training.py
```

**What happens:**
1. Loads standardized residuals from Phase 4
2. Trains a Normalizing Flow model for each model-asset combination
3. Generates synthetic residuals that preserve statistical properties
4. Saves trained models and synthetic residuals

**Mathematical Verification After Training:**

```python
import numpy as np
from scipy.stats import ks_2samp, wasserstein_distance

# Load real and synthetic residuals
real_residuals = np.loadtxt('outputs/manual/residuals_by_model/sGARCH/NVDA_Manual_Optimized_residuals.csv')
synthetic_residuals = np.loadtxt('outputs/manual/nf_models/sGARCH_NVDA_synthetic_residuals.csv')

# Check statistical properties
print(f"Real - Mean: {np.mean(real_residuals):.4f}, Std: {np.std(real_residuals):.4f}")
print(f"Synth - Mean: {np.mean(synthetic_residuals):.4f}, Std: {np.std(synthetic_residuals):.4f}")

# Kolmogorov-Smirnov test (should not reject H0: same distribution)
ks_stat, ks_pval = ks_2samp(real_residuals, synthetic_residuals)
print(f"KS test: stat={ks_stat:.4f}, p-value={ks_pval:.4f}")

# Wasserstein distance (should be small)
wd = wasserstein_distance(real_residuals, synthetic_residuals)
print(f"Wasserstein distance: {wd:.4f}")
```

**Expected:**
- Mean differences < 0.1
- Std differences < 0.2
- KS p-value > 0.05 (same distribution)
- Wasserstein distance < 0.3

**Outputs:**
- `outputs/manual/nf_models/*_synthetic_residuals.csv` - Synthetic residuals
- `outputs/manual/nf_models/*/nf_model.pth` - Trained PyTorch models

---

## üîÑ Phase 6: NF-GARCH Simulation (15-20 minutes)

### Step 6.1: Run NF-GARCH Simulation
```r
# In RStudio or R Console
# Load engine selector
source("scripts/engines/engine_selector.R")
source("scripts/utils/cli_parser.R")

# Run simulation
Rscript scripts/simulation_forecasting/simulate_nf_garch_engine.R --engine manual
```

**What happens:**
1. Loads trained GARCH models and synthetic residuals
2. For each model-asset combination:
   - Fits GARCH model to historical returns
   - Generates synthetic path using: r_t = Œº + œÉ_t * z_synthetic
   - Where œÉ_t follows GARCH recursion with synthetic innovations
3. Compares simulated vs actual returns (MSE, MAE)
4. Performs time-series cross-validation

**Mathematical Verification During Simulation:**

For NF-GARCH simulation, verify the path generation:
```r
# After simulation, check:
sim_result <- your_simulation_result

# 1. Variance follows GARCH equation
# œÉ¬≤_{t+1} should equal: œâ + Œ±*Œµ¬≤_t + Œ≤*œÉ¬≤_t
sigma2_manual <- omega + alpha*residuals^2 + beta*sigma2_lag
all.equal(sigma2_garch, sigma2_manual, tolerance = 1e-6)

# 2. Returns follow: r_t = Œº + œÉ_t * z_t
returns_sim <- mu + sigma * synthetic_z
cor(returns_sim, actual_returns)  # Should be positive but not 1.0

# 3. Synthetic returns preserve volatility clustering
acf(returns_sim^2)  # Should show autocorrelation
acf(actual_returns^2)  # Should show similar pattern
```

**Expected Outputs:**
- `results/consolidated/NF_GARCH_Results_manual.xlsx` - Complete results
- Comparison tables showing:
  - Chronological split performance
  - Time-series CV performance
  - Model rankings

**Key Metrics:**
- MSE: Mean Squared Error between simulated and actual
- MAE: Mean Absolute Error
- AIC/BIC: Model selection criteria

---

## üìà Phase 7: Results Verification (10 minutes)

### Step 7.1: Check Output Files
```r
# Verify all outputs exist
output_files <- list(
  garch_summary = "outputs/manual/garch_fitting/model_summary.csv",
  nf_training = "outputs/manual/nf_models/training_summary.json",
  simulation_results = "results/consolidated/NF_GARCH_Results_manual.xlsx"
)

sapply(output_files, file.exists)
# All should return TRUE
```

### Step 7.2: Validate Mathematical Properties

```r
# Load results
library(openxlsx)
results <- read.xlsx("results/consolidated/NF_GARCH_Results_manual.xlsx", 
                     sheet = "Chrono_Split_NF_GARCH")

# Check each model-asset combination:
# 1. AIC and BIC are finite and reasonable
all(is.finite(results$AIC))
all(is.finite(results$BIC))
summary(results$AIC)  # Should show reasonable range

# 2. MSE and MAE are positive
all(results$MSE > 0)
all(results$MAE > 0)

# 3. Log-likelihood is negative (typical)
all(results$LogLikelihood < 0)

# 4. Compare models - lower AIC/BIC is better
results %>%
  group_by(Model) %>%
  summarise(
    Mean_AIC = mean(AIC, na.rm = TRUE),
    Mean_BIC = mean(BIC, na.rm = TRUE),
    Mean_MSE = mean(MSE, na.rm = TRUE)
  ) %>%
  arrange(Mean_AIC)
```

---

## üéì Mathematical Reference Checklist

Use this checklist to verify correctness at each step:

### GARCH Model Equations ‚úì

**sGARCH(1,1):**
- Return: r_t = Œº + Œµ_t
- Error: Œµ_t = œÉ_t * z_t (where z_t ~ N(0,1) or t-distribution)
- Variance: œÉ¬≤_t = œâ + Œ±Œµ¬≤_{t-1} + Œ≤œÉ¬≤_{t-1}
- Constraints: œâ > 0, Œ± ‚â• 0, Œ≤ ‚â• 0, Œ± + Œ≤ < 1

**eGARCH(1,1):**
- Return: r_t = Œº + Œµ_t
- Log-variance: log(œÉ¬≤_t) = œâ + Œ±(|z_{t-1}| - E|z_t|) + Œ≥z_{t-1} + Œ≤log(œÉ¬≤_{t-1})
- Constraints: Œ≤ < 1 (stationarity)

**gjrGARCH(1,1):**
- Variance: œÉ¬≤_t = œâ + Œ±Œµ¬≤_{t-1} + Œ≥Œµ¬≤_{t-1}I_{Œµ<0} + Œ≤œÉ¬≤_{t-1}
- Constraints: œâ > 0, Œ± ‚â• 0, Œ≥ ‚â• 0, Œ≤ ‚â• 0, Œ± + Œ≥/2 + Œ≤ < 1

**TGARCH(1,1):**
- Variance: œÉ¬≤_t = œâ + (Œ± + Œ∑I_{Œµ<0})Œµ¬≤_{t-1} + Œ≤œÉ¬≤_{t-1}
- Constraints: Similar to gjrGARCH

### Likelihood Functions ‚úì

**Normal Distribution:**
- Log-likelihood: LL = -¬ΩŒ£[log(2œÄ) + log(œÉ¬≤_t) + (Œµ_t/œÉ_t)¬≤]

**Student-t Distribution:**
- Log-likelihood: Includes gamma functions and degrees of freedom ŒΩ

### Residual Standardization ‚úì

- Standardized residual: z_t = Œµ_t / œÉ_t
- Should have: E[z_t] ‚âà 0, Var(z_t) ‚âà 1
- Should be: i.i.d. (independent and identically distributed)

### NF-GARCH Simulation ‚úì

1. Initialize: œÉ¬≤_0 = unconditional variance
2. For each time step t:
   - Draw synthetic innovation: z_synth ~ NF(learned distribution)
   - Update variance: œÉ¬≤_t = GARCH_recursion(œÉ¬≤_{t-1}, Œµ_{t-1})
   - Generate return: r_t = Œº + œÉ_t * z_synth
   - Calculate error: Œµ_t = r_t - Œº

---

## üêõ Troubleshooting

### If GARCH fitting fails:
1. Check data quality (no NAs, sufficient observations > 500)
2. Try different initial parameter values
3. Check convergence code (should be 0 for success)
4. Verify returns are stationary

### If NF training fails:
1. Verify residual files exist and have data
2. Check Python packages are installed correctly
3. Ensure enough memory (NF training can be memory-intensive)
4. Try reducing batch size or epochs

### If simulation fails:
1. Verify synthetic residuals are loaded correctly
2. Check GARCH model fits exist
3. Ensure file paths are correct
4. Verify engine selector is using "manual" engine

---

## ‚úÖ Final Verification

After completing all phases, verify:

1. ‚úì All output files exist
2. ‚úì All models converged (convergence rate > 90%)
3. ‚úì Residuals are properly standardized (mean ‚âà 0, var ‚âà 1)
4. ‚úì Synthetic residuals preserve distribution (KS test p > 0.05)
5. ‚úì Simulation produces realistic returns (volatility clustering, fat tails)
6. ‚úì Results Excel file contains all expected sheets
7. ‚úì Mathematical equations are correctly implemented (verification script passes)

**You're done!** The manual engine pipeline has been successfully executed with mathematical verification at each step.

For NF-GARCH simulation, verify the path generation:
```r
# After simulation, check:
sim_result <- your_simulation_result

# 1. Variance follows GARCH equation
# œÉ¬≤_{t+1} should equal: œâ + Œ±*Œµ¬≤_t + Œ≤*œÉ¬≤_t
sigma2_manual <- omega + alpha*residuals^2 + beta*sigma2_lag
all.equal(sigma2_garch, sigma2_manual, tolerance = 1e-6)

# 2. Returns follow: r_t = Œº + œÉ_t * z_t
returns_sim <- mu + sigma * synthetic_z
cor(returns_sim, actual_returns)  # Should be positive but not 1.0

# 3. Synthetic returns preserve volatility clustering
acf(returns_sim^2)  # Should show autocorrelation
acf(actual_returns^2)  # Should show similar pattern
```

**Expected Outputs:**
- `results/consolidated/NF_GARCH_Results_manual.xlsx` - Complete results
- Comparison tables showing:
  - Chronological split performance
  - Time-series CV performance
  - Model rankings

**Key Metrics:**
- MSE: Mean Squared Error between simulated and actual
- MAE: Mean Absolute Error
- AIC/BIC: Model selection criteria

---

## üìà Phase 7: Results Verification (10 minutes)

### Step 7.1: Check Output Files
```r
# Verify all outputs exist
output_files <- list(
  garch_summary = "outputs/manual/garch_fitting/model_summary.csv",
  nf_training = "outputs/manual/nf_models/training_summary.json",
  simulation_results = "results/consolidated/NF_GARCH_Results_manual.xlsx"
)

sapply(output_files, file.exists)
# All should return TRUE
```

### Step 7.2: Validate Mathematical Properties

```r
# Load results
library(openxlsx)
results <- read.xlsx("results/consolidated/NF_GARCH_Results_manual.xlsx", 
                     sheet = "Chrono_Split_NF_GARCH")

# Check each model-asset combination:
# 1. AIC and BIC are finite and reasonable
all(is.finite(results$AIC))
all(is.finite(results$BIC))
summary(results$AIC)  # Should show reasonable range

# 2. MSE and MAE are positive
all(results$MSE > 0)
all(results$MAE > 0)

# 3. Log-likelihood is negative (typical)
all(results$LogLikelihood < 0)

# 4. Compare models - lower AIC/BIC is better
results %>%
  group_by(Model) %>%
  summarise(
    Mean_AIC = mean(AIC, na.rm = TRUE),
    Mean_BIC = mean(BIC, na.rm = TRUE),
    Mean_MSE = mean(MSE, na.rm = TRUE)
  ) %>%
  arrange(Mean_AIC)
```

---

## üéì Mathematical Reference Checklist

Use this checklist to verify correctness at each step:

### GARCH Model Equations ‚úì

**sGARCH(1,1):**
- Return: r_t = Œº + Œµ_t
- Error: Œµ_t = œÉ_t * z_t (where z_t ~ N(0,1) or t-distribution)
- Variance: œÉ¬≤_t = œâ + Œ±Œµ¬≤_{t-1} + Œ≤œÉ¬≤_{t-1}
- Constraints: œâ > 0, Œ± ‚â• 0, Œ≤ ‚â• 0, Œ± + Œ≤ < 1

**eGARCH(1,1):**
- Return: r_t = Œº + Œµ_t
- Log-variance: log(œÉ¬≤_t) = œâ + Œ±(|z_{t-1}| - E|z_t|) + Œ≥z_{t-1} + Œ≤log(œÉ¬≤_{t-1})
- Constraints: Œ≤ < 1 (stationarity)

**gjrGARCH(1,1):**
- Variance: œÉ¬≤_t = œâ + Œ±Œµ¬≤_{t-1} + Œ≥Œµ¬≤_{t-1}I_{Œµ<0} + Œ≤œÉ¬≤_{t-1}
- Constraints: œâ > 0, Œ± ‚â• 0, Œ≥ ‚â• 0, Œ≤ ‚â• 0, Œ± + Œ≥/2 + Œ≤ < 1

**TGARCH(1,1):**
- Variance: œÉ¬≤_t = œâ + (Œ± + Œ∑I_{Œµ<0})Œµ¬≤_{t-1} + Œ≤œÉ¬≤_{t-1}
- Constraints: Similar to gjrGARCH

### Likelihood Functions ‚úì

**Normal Distribution:**
- Log-likelihood: LL = -¬ΩŒ£[log(2œÄ) + log(œÉ¬≤_t) + (Œµ_t/œÉ_t)¬≤]

**Student-t Distribution:**
- Log-likelihood: Includes gamma functions and degrees of freedom ŒΩ

### Residual Standardization ‚úì

- Standardized residual: z_t = Œµ_t / œÉ_t
- Should have: E[z_t] ‚âà 0, Var(z_t) ‚âà 1
- Should be: i.i.d. (independent and identically distributed)

### NF-GARCH Simulation ‚úì

1. Initialize: œÉ¬≤_0 = unconditional variance
2. For each time step t:
   - Draw synthetic innovation: z_synth ~ NF(learned distribution)
   - Update variance: œÉ¬≤_t = GARCH_recursion(œÉ¬≤_{t-1}, Œµ_{t-1})
   - Generate return: r_t = Œº + œÉ_t * z_synth
   - Calculate error: Œµ_t = r_t - Œº

---

## üêõ Troubleshooting

### If GARCH fitting fails:
1. Check data quality (no NAs, sufficient observations > 500)
2. Try different initial parameter values
3. Check convergence code (should be 0 for success)
4. Verify returns are stationary

### If NF training fails:
1. Verify residual files exist and have data
2. Check Python packages are installed correctly
3. Ensure enough memory (NF training can be memory-intensive)
4. Try reducing batch size or epochs

### If simulation fails:
1. Verify synthetic residuals are loaded correctly
2. Check GARCH model fits exist
3. Ensure file paths are correct
4. Verify engine selector is using "manual" engine

---

## ‚úÖ Final Verification

After completing all phases, verify:

1. ‚úì All output files exist
2. ‚úì All models converged (convergence rate > 90%)
3. ‚úì Residuals are properly standardized (mean ‚âà 0, var ‚âà 1)
4. ‚úì Synthetic residuals preserve distribution (KS test p > 0.05)
5. ‚úì Simulation produces realistic returns (volatility clustering, fat tails)
6. ‚úì Results Excel file contains all expected sheets
7. ‚úì Mathematical equations are correctly implemented (verification script passes)

**You're done!** The manual engine pipeline has been successfully executed with mathematical verification at each step.

This guide provides step-by-step instructions for running the Financial-SDG-GARCH pipeline manually in R Studio and Jupyter Notebook with significant optimizations.

## üöÄ Optimization Summary

- **Asset Reduction**: 50% time savings (12 ‚Üí 6 assets)
- **Model Reduction**: 40% time savings (5 ‚Üí 3 models)  
- **CV Optimization**: 60% time savings (5 ‚Üí 3 folds, optimized windows)
- **NF Training**: 25% time savings (100 ‚Üí 75 epochs, optimized architecture)
- **Total Expected Time Savings**: 70-80%
- **Expected Execution Time**: 45-90 minutes

## üìã Prerequisites

### R Packages Required
```r
install.packages(c(
  "rugarch", "quantmod", "xts", "PerformanceAnalytics", 
  "FinTS", "tidyverse", "dplyr", "tidyr", "stringr", 
  "ggplot2", "openxlsx", "moments", "tseries", 
  "forecast", "lmtest", "parallel", "doParallel"
))
```

### Python Packages Required
```bash
pip install torch nflows numpy pandas matplotlib scipy psutil
```

## üîß Manual Execution Steps

### Phase 1: R Studio - Data Preparation & GARCH Fitting (30 minutes)

#### Step 1: Load Configuration
```r
# Load optimized configuration
source("scripts/manual/manual_optimized_config.R")

# Verify optimization settings
print_optimization_summary()
```

#### Step 2: Run Optimized GARCH Fitting
```r
# Run the optimized GARCH fitting script
source("scripts/manual/manual_garch_fitting.R")
```

**What this does:**
- Loads 6 optimized assets (3 FX + 3 Equity)
- Fits 3 optimized GARCH models (sGARCH, eGARCH, TGARCH)
- Runs optimized time-series cross-validation (3 folds instead of 5)
- Saves residuals for NF training

**Expected Output:**
- `outputs/manual/garch_fitting/model_summary.csv`
- `outputs/manual/residuals_by_model/` (residuals for each model-asset combination)

### Phase 2: Jupyter Notebook - NF Training (20 minutes)

#### Step 1: Open Jupyter Notebook
```bash
jupyter notebook
```

#### Step 2: Create New Notebook or Use Existing
Create a new notebook or use: `archive/Manual Scripts/Python - NF Main Training/NFGARCH - Train all Residuals.ipynb`

#### Step 3: Run Optimized NF Training
```python
# Cell 1: Import and setup
exec(open('scripts/manual/manual_nf_training.py').read())

# Cell 2: Run main training pipeline
training_results, all_samples = main()
```

**What this does:**
- Trains NF models on GARCH residuals (75 epochs instead of 100)
- Uses optimized architecture (4 layers, 64 hidden features)
- Implements early stopping and validation
- Generates synthetic residuals

**Expected Output:**
- `outputs/manual/nf_models/` (trained NF models)
- `outputs/manual/nf_models/*_synthetic_residuals.csv` (synthetic data)

### Phase 3: R Studio - Simulation & Evaluation (15 minutes)

#### Step 1: Run NF-GARCH Simulation
```r
# Load the main simulation script with manual optimizations
source("scripts/simulation_forecasting/simulate_nf_garch_engine.R")
```

#### Step 2: Run Core Evaluation
```r
# Run only essential evaluation metrics
source("scripts/evaluation/core_metrics.R")
```

**What this does:**
- Simulates NF-GARCH models with synthetic residuals
- Evaluates core metrics (RMSE, MAE, KS distance, VaR)
- Skips non-essential evaluations for speed

## üìä Optimization Details

### Asset Selection (50% Reduction)
**Selected Assets:**
- **FX**: EURUSD, GBPUSD, USDZAR (3 most liquid)
- **Equity**: NVDA, MSFT, AMZN (3 most volatile)

**Excluded Assets:**
- **FX**: GBPCNY, GBPZAR, EURZAR
- **Equity**: PG, CAT, WMT

### Model Selection (40% Reduction)
**Selected Models:**
- **sGARCH**: Standard GARCH with skewed t-distribution
- **eGARCH**: Exponential GARCH with asymmetric effects
- **TGARCH**: Threshold GARCH with regime-dependent behavior

**Excluded Models:**
- **sGARCH_norm**: Standard GARCH with normal distribution
- **gjrGARCH**: Glosten-Jagannathan-Runkle GARCH

### CV Optimization (60% Time Savings)
**Optimized Parameters:**
- **Folds**: 3 (reduced from 5)
- **Window Size**: 50% (reduced from 65%)
- **Step Size**: 15% (increased from 10%)
- **Max Windows**: 3 (reduced from 4)
- **Forecast Horizon**: 15 (reduced from 20)

### NF Training Optimization (25% Time Savings)
**Optimized Parameters:**
- **Epochs**: 75 (reduced from 100)
- **Batch Size**: 512 (increased from 256)
- **Layers**: 4 (reduced from 5)
- **Hidden Features**: 64 (reduced from 128)
- **Early Stopping**: Enabled (patience = 15)

## üîç Monitoring and Debugging

### Performance Monitoring
```r
# In R Studio - Monitor execution time
start_time <- Sys.time()
# Your code here
end_time <- Sys.time()
cat("Execution time:", end_time - start_time, "\n")
```

```python
# In Jupyter - Monitor memory usage
monitor_memory()
clear_memory()  # Clear GPU/CPU memory
```

### Common Issues and Solutions

#### Issue 1: Memory Errors
**Solution:**
```r
# Clear memory between operations
gc()
```

```python
# Clear GPU memory
clear_memory()
```

#### Issue 2: Convergence Failures
**Solution:**
- Check data quality
- Reduce model complexity
- Increase tolerance parameters

#### Issue 3: Slow Execution
**Solution:**
- Enable parallel processing
- Reduce batch sizes
- Skip non-essential components

## üìà Expected Results

### Performance Metrics
- **Total Execution Time**: 45-90 minutes
- **Memory Usage**: < 8GB
- **Success Rate**: > 90%
- **Convergence Rate**: > 85%

### Output Files
```
outputs/manual/
‚îú‚îÄ‚îÄ garch_fitting/
‚îÇ   ‚îú‚îÄ‚îÄ model_summary.csv
‚îÇ   ‚îî‚îÄ‚îÄ detailed_results.rds
‚îú‚îÄ‚îÄ residuals_by_model/
‚îÇ   ‚îú‚îÄ‚îÄ sGARCH/
‚îÇ   ‚îú‚îÄ‚îÄ eGARCH/
‚îÇ   ‚îî‚îÄ‚îÄ TGARCH/
‚îú‚îÄ‚îÄ nf_models/
‚îÇ   ‚îú‚îÄ‚îÄ sGARCH_*_synthetic_residuals.csv
‚îÇ   ‚îú‚îÄ‚îÄ eGARCH_*_synthetic_residuals.csv
‚îÇ   ‚îî‚îÄ‚îÄ TGARCH_*_synthetic_residuals.csv
‚îî‚îÄ‚îÄ evaluation/
    ‚îú‚îÄ‚îÄ core_metrics.csv
    ‚îî‚îÄ‚îÄ simulation_results.csv
```

## üéØ Quick Start Commands

### Ultra-Fast Execution (45 minutes)
```r
# R Studio
source("scripts/manual/manual_optimized_config.R")
source("scripts/manual/manual_garch_fitting.R")
```

```python
# Jupyter Notebook
exec(open('scripts/manual/manual_nf_training.py').read())
training_results, all_samples = main()
```

### Balanced Execution (90 minutes)
```r
# R Studio - Full pipeline with more assets/models
source("scripts/core/config.R")  # Use full config
source("scripts/model_fitting/fit_garch_models.R")
source("scripts/model_fitting/extract_residuals.R")
source("scripts/simulation_forecasting/simulate_nf_garch_engine.R")
```

## üìù Notes

1. **First Run**: May take longer due to package compilation
2. **Memory**: Ensure at least 8GB RAM available
3. **GPU**: Optional but recommended for NF training
4. **Parallel Processing**: Automatically enabled where possible
5. **Checkpoints**: Results are saved incrementally

## üÜò Troubleshooting

### If Scripts Fail
1. Check file paths and working directory
2. Verify all required packages are installed
3. Check memory usage and clear if needed
4. Review error messages in console output

### If Results Are Incomplete
1. Check convergence rates in model summary
2. Verify residual files were generated
3. Ensure NF training completed successfully
4. Check output directories for missing files

## üìû Support

For issues or questions:
1. Check the `outputs/manual/` directory for logs
2. Review error messages in console output
3. Verify optimization settings with `print_optimization_summary()`
4. Check memory usage with monitoring functions

